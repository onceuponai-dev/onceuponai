templates:
  - id: e5
    kind: e5
    device: cpu
    sidecar: onceuponai-actors-candle
    metadata:
      name: e5
      description: ""
      url: ""
    spec:
      - key: model_repo
        value: intfloat/multilingual-e5-small
        type: string
      - key: hf_token
        value: null
        type: secret


  - id: gemma
    kind: gemma
    device: cpu
    sidecar: onceuponai-actors-candle
    metadata:
      name: gemma
      description: ""
      url: ""
    spec:
      - key: base_repo_id
        value: google/gemma-2b-it
        type: string
      - key: tokenizer_repo
        value: google/gemma-2b-it
        type: string
      - key: seed
        value: 299792458
        type: number
      - key: repeat_last_n
        value: 64
        type: number
      - key: repeat_penalty
        value: 1.1
        type: number
      - key: temp
        value: 0.8
        type: number
      - key: top_p
        value: null
        type: number
      - key: hf_token
        value: null
        type: secret
      - key: use_flash_attn
        value: false
        type: bool
      - key: sample_len
        value: 1000
        type: number

  - id: quantized
    sidecar: onceuponai-actors-candle
    kind: quantized
    device: cuda
    metadata:
      name: quantized
      description: ""
      url: ""
    spec:
      - key: model_repo
        value: speakleash/Bielik-7B-Instruct-v0.1-GGUF
        type: string
      - key: model_file
        value: bielik-7b-instruct-v0.1.Q4_K_S.gguf
        type: string
      - key: model_revision
        value: null
        type: string
      - key: tokenizer_repo
        value: speakleash/Bielik-7B-Instruct-v0.1
        type: string
      - key: seed
        value: 299792458
        type: number
      - key: repeat_last_n
        value: 64
        type: number
      - key: repeat_penalty
        value: 1.1
        type: number
      - key: temp
        value: 0.8
        type: number
      - key: top_p
        value: null
        type: number
      - key: top_k
        value: null
        type: number
      - key: sample_len
        value: 1000
        type: number
      - key: gqa
        value: 8
        type: number
      - key: force_dmmv
        value: false
        type: bool
      - key: eos_token
        value: </s>
        type: string
      - key: hf_token
        value: null
        type: secret



galery:
  # E5 MODELS
  - id: e5/multilingual-e5-small
    template: e5
    device: cpu
    metadata:
      name: multilingual-e5-small
      description: ""
      url: ""
    spec:
      - key: model_repo
        value: intfloat/multilingual-e5-small
        type: string

  - id: e5/multilingual-e5-large
    template: e5
    device: cpu
    metadata:
      name: multilingual-e5-large
      description: ""
      url: ""
    spec:
      - key: model_repo
        value: intfloat/multilingual-e5-large
        type: string

  - id: e5/e5-small-v2
    template: e5
    device: cpu
    metadata:
      name: e5-small-v2
      description: ""
      url: ""
    spec:
      - key: model_repo
        value: intfloat/e5-small-v2
        type: string

  - id: e5/e5-large-v2
    template: e5
    device: cpu
    metadata:
      name: e5-large-v2
      description: ""
      url: ""
    spec:
      - key: model_repo
        value: intfloat/e5-large-v2
        type: string



  # GEMMA MODELS
  - id: gemma/gemma-2b-it
    template: gemma
    device: cpu
    metadata:
      name: gemma-2b-it
      description: ""
      url: ""
    spec:
      - key: base_repo_id
        value: google/gemma-2b-it
        type: string
      - key: tokenizer_repo
        value: google/gemma-2b-it
        type: string


  # QUANTIZED MODELS
  - id: quantized/bielik-7b
    template: quantized
    device: cuda
    metadata:
      name: bielik-7b
      description: ""
      url: ""
    spec:
      - key: model_repo
        value: speakleash/Bielik-7B-Instruct-v0.1-GGUF
        type: string
      - key: model_file
        value: bielik-7b-instruct-v0.1.Q4_K_S.gguf
        type: string
      - key: tokenizer_repo
        value: speakleash/Bielik-7B-Instruct-v0.1
        type: string

  - id: quantized/bielik-11b
    template: quantized
    device: cuda
    metadata:
      name: bielik-11b
      description: ""
      url: ""
    spec:
      - key: model_repo
        value: speakleash/Bielik-11B-v2.2-Instruct-GGUF
        type: string
      - key: model_file
        value: Bielik-11B-v2.2-Instruct.Q4_K_M.gguf
        type: string
      - key: tokenizer_repo
        value: speakleash/Bielik-11B-v2.2-Instruct
        type: string


  - id: quantized/l7b
    template: quantized
    device: cuda
    metadata:
      name: l7b
      description: ""
      url: ""
    spec:
      - key: model_repo
        value: TheBloke/Llama-2-7B-GGML
        type: string
      - key: model_file
        value: llama-2-7b.ggmlv3.q4_0.bin
        type: string
      - key: tokenizer_repo
        value: hf-internal-testing/llama-tokenizer
        type: string
      - key: gqa
        value: 1
        type: number


  - id: quantized/l13b
    template: quantized
    device: cuda
    metadata:
      name: l13b
      description: ""
      url: ""
    spec:
      - key: model_repo
        value: TheBloke/Llama-2-13B-GGML
        type: string
      - key: model_file
        value: llama-2-13b.ggmlv3.q4_0.bin
        type: string
      - key: tokenizer_repo
        value: hf-internal-testing/llama-tokenizer
        type: string
      - key: gqa
        value: 1
        type: number


  - id: quantized/l70b
    template: quantized
    device: cuda
    metadata:
      name: l70b
      description: ""
      url: ""
    spec:
      - key: model_repo
        value: TheBloke/Llama-2-70B-GGML
        type: string
      - key: model_file
        value: llama-2-70b.ggmlv3.q4_0.bin
        type: string
      - key: tokenizer_repo
        value: hf-internal-testing/llama-tokenizer
        type: string


  - id: quantized/l7b-chat
    template: quantized
    device: cuda
    metadata:
      name: l7b-chat
      description: ""
      url: ""
    spec:
      - key: model_repo
        value: TheBloke/Llama-2-7B-Chat-GGML
        type: string
      - key: model_file
        value: llama-2-7b-chat.ggmlv3.q4_0.bin
        type: string
      - key: tokenizer_repo
        value: hf-internal-testing/llama-tokenizer
        type: string
      - key: gqa
        value: 1
        type: number


  - id: quantized/l13b-chat
    template: quantized
    device: cuda
    metadata:
      name: l13b-chat
      description: ""
      url: ""
    spec:
      - key: model_repo
        value: TheBloke/Llama-2-13B-Chat-GGML
        type: string
      - key: model_file
        value: llama-2-13b-chat.ggmlv3.q4_0.bin
        type: string
      - key: tokenizer_repo
        value: hf-internal-testing/llama-tokenizer
        type: string
      - key: gqa
        value: 1
        type: number


  - id: quantized/l70b-chat
    template: quantized
    device: cuda
    metadata:
      name: l70b-chat
      description: ""
      url: ""
    spec:
      - key: model_repo
        value: TheBloke/Llama-2-70B-Chat-GGML
        type: string
      - key: model_file
        value: llama-2-70b-chat.ggmlv3.q4_0.bin
        type: string
      - key: tokenizer_repo
        value: hf-internal-testing/llama-tokenizer
        type: string

  - id: quantized/l7b-code
    template: quantized
    device: cuda
    metadata:
      name: l7b-code
      description: ""
      url: ""
    spec:
      - key: model_repo
        value: TheBloke/CodeLlama-7B-GGUF
        type: string
      - key: model_file
        value: codellama-7b.Q8_0.gguf
        type: string
      - key: tokenizer_repo
        value: hf-internal-testing/llama-tokenizer
        type: string
      - key: gqa
        value: 1
        type: number


  - id: quantized/l13b-code
    template: quantized
    device: cuda
    metadata:
      name: l13b-code
      description: ""
      url: ""
    spec:
      - key: model_repo
        value: TheBloke/CodeLlama-13B-GGUF
        type: string
      - key: model_file
        value: codellama-13b.Q8_0.gguf
        type: string
      - key: tokenizer_repo
        value: hf-internal-testing/llama-tokenizer
        type: string
      - key: gqa
        value: 1
        type: number


  - id: quantized/l34b-code
    template: quantized
    device: cuda
    metadata:
      name: l34b-code
      description: ""
      url: ""
    spec:
      - key: model_repo
        value: TheBloke/CodeLlama-34B-GGUF
        type: string
      - key: model_file
        value: codellama-34b.Q8_0.gguf
        type: string
      - key: tokenizer_repo
        value: hf-internal-testing/llama-tokenizer
        type: string
      - key: gqa
        value: 1
        type: number


  - id: quantized/leo7b
    template: quantized
    device: cuda
    metadata:
      name: leo7b
      description: ""
      url: ""
    spec:
      - key: model_repo
        value: TheBloke/leo-hessianai-7B-GGUF
        type: string
      - key: model_file
        value: leo-hessianai-7b.Q4_K_M.gguf
        type: string
      - key: tokenizer_repo
        value: LeoLM/leo-hessianai-7b
        type: string
      - key: gqa
        value: 1
        type: number


  - id: quantized/leo13b
    template: quantized
    device: cuda
    metadata:
      name: leo13b
      description: ""
      url: ""
    spec:
      - key: model_repo
        value: TheBloke/leo-hessianai-13B-GGUF
        type: string
      - key: model_file
        value: leo-hessianai-13b.Q4_K_M.gguf
        type: string
      - key: tokenizer_repo
        value: LeoLM/leo-hessianai-13b
        type: string
      - key: gqa
        value: 1
        type: number


  - id: quantized/mixtral
    template: quantized
    device: cuda
    metadata:
      name: mixtral
      description: ""
      url: ""
    spec:
      - key: model_repo
        value: TheBloke/Mixtral-8x7B-v0.1-GGUF
        type: string
      - key: model_file
        value: mixtral-8x7b-v0.1.Q4_K_M.gguf
        type: string
      - key: tokenizer_repo
        value: mistralai/Mixtral-8x7B-v0.1
        type: string

  - id: quantized/mixtral-instruct
    template: quantized
    device: cuda
    metadata:
      name: mixtral-instruct
      description: ""
      url: ""
    spec:
      - key: model_repo
        value: TheBloke/Mixtral-8x7B-Instruct-v0.1-GGUF
        type: string
      - key: model_file
        value: mixtral-8x7b-instruct-v0.1.Q4_K_M.gguf
        type: string
      - key: tokenizer_repo
        value: mistralai/Mixtral-8x7B-Instruct-v0.1
        type: string

  - id: quantized/mistral7b
    template: quantized
    device: cuda
    metadata:
      name: mistral7b
      description: ""
      url: ""
    spec:
      - key: model_repo
        value: TheBloke/Mistral-7B-v0.1-GGUF
        type: string
      - key: model_file
        value: mistral-7b-v0.1.Q4_K_S.gguf
        type: string
      - key: tokenizer_repo
        value: mistralai/Mistral-7B-v0.1
        type: string

  - id: quantized/mistral7b-instruct
    template: quantized
    device: cuda
    metadata:
      name: mistral7b-instruct
      description: ""
      url: ""
    spec:
      - key: model_repo
        value: TheBloke/Mistral-7B-Instruct-v0.1-GGUF
        type: string
      - key: model_file
        value: mistral-7b-instruct-v0.1.Q4_K_S.gguf
        type: string
      - key: tokenizer_repo
        value: mistralai/Mistral-7B-v0.1
        type: string

  - id: quantized/mistral7b-instruct-v02
    template: quantized
    device: cuda
    metadata:
      name: mistral7b-instruct-v02
      description: ""
      url: ""
    spec:
      - key: model_repo
        value: TheBloke/Mistral-7B-Instruct-v0.2-GGUF
        type: string
      - key: model_file
        value: mistral-7b-instruct-v0.2.Q4_K_S.gguf
        type: string
      - key: tokenizer_repo
        value: mistralai/Mistral-7B-v0.1
        type: string

  - id: quantized/zephyr7b-alpha
    template: quantized
    device: cuda
    metadata:
      name: zephyr7b-alpha
      description: ""
      url: ""
    spec:
      - key: model_repo
        value: TheBloke/zephyr-7B-alpha-GGUF
        type: string
      - key: model_file
        value: zephyr-7b-alpha.Q4_K_M.gguf
        type: string
      - key: tokenizer_repo
        value: mistralai/Mistral-7B-v0.1
        type: string

  - id: quantized/zephyr7b-beta
    template: quantized
    device: cuda
    metadata:
      name: zephyr7b-beta
      description: ""
      url: ""
    spec:
      - key: model_repo
        value: TheBloke/zephyr-7B-beta-GGUF
        type: string
      - key: model_file
        value: zephyr-7b-beta.Q4_K_M.gguf
        type: string
      - key: tokenizer_repo
        value: mistralai/Mistral-7B-v0.1
        type: string

  - id: quantized/openchat35
    template: quantized
    device: cuda
    metadata:
      name: openchat35
      description: ""
      url: ""
    spec:
      - key: model_repo
        value: TheBloke/openchat_3.5-GGUF
        type: string
      - key: model_file
        value: openchat_3.5.Q4_K_M.gguf
        type: string
      - key: tokenizer_repo
        value: openchat/openchat_3.5
        type: string
      - key: eos_token
        value: <|end_of_text|>
        type: string


  - id: quantized/starling7b-alpha
    template: quantized
    device: cuda
    metadata:
      name: starling7b-alpha
      description: ""
      url: ""
    spec:
      - key: model_repo
        value: TheBloke/Starling-LM-7B-alpha-GGUF
        type: string
      - key: model_file
        value: starling-lm-7b-alpha.Q4_K_M.gguf
        type: string
      - key: tokenizer_repo
        value: berkeley-nest/Starling-LM-7B-alpha
        type: string
      - key: eos_token
        value: <|end_of_text|>
        type: string


  - id: quantized/l8b
    template: quantized
    device: cuda
    metadata:
      name: l8b
      description: ""
      url: ""
    spec:
      - key: model_repo
        value: QuantFactory/Meta-Llama-3-8B-GGUF
        type: string
      - key: model_file
        value: Meta-Llama-3-8B.Q4_K_S.gguf
        type: string
      - key: tokenizer_repo
        value: meta-llama/Meta-Llama-3-8B
        type: string
      - key: gqa
        value: 1
        type: number
      - key: eos_token
        value: <|end_of_text|>
        type: string



  - id: quantized/phi3
    template: quantized
    device: cuda
    metadata:
      name: phi3
      description: ""
      url: ""
    spec:
      - key: model_repo
        value: microsoft/Phi-3-mini-4k-instruct-gguf
        type: string
      - key: model_file
        value: Phi-3-mini-4k-instruct-q4.gguf
        type: string
      - key: tokenizer_repo
        value: microsoft/Phi-3-mini-4k-instruct
        type: string
      - key: model_revision
        value: 5eef2ce24766d31909c0b269fe90c817a8f263fb
        type: string
      - key: gqa
        value: 1
        type: number


